{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XRF Data Exploratory Data Analysis\n",
    "\n",
    "This notebook walks through a complete EDA workflow for XRF fluorescence microscopy\n",
    "data stored in MAPS HDF5 format. We inspect elemental maps, compute per-channel\n",
    "statistics, assess signal-to-noise ratio, build correlation matrices, detect dead\n",
    "pixels, and check I0 normalization.\n",
    "\n",
    "**Prerequisites**: `pip install h5py numpy matplotlib seaborn scipy pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "# Update this path to your XRF HDF5 file\n",
    "FILEPATH = \"xrf_scan.h5\"\n",
    "\n",
    "# Load data\n",
    "with h5py.File(FILEPATH, \"r\") as f:\n",
    "    maps = f[\"MAPS/XRF_Analyzed/Fitted/Counts_Per_Sec\"][:]\n",
    "    names = [n.decode() for n in f[\"MAPS/XRF_Analyzed/Channel_Names\"][:]]\n",
    "    x_axis = f[\"MAPS/Scan/x_axis\"][:]\n",
    "    y_axis = f[\"MAPS/Scan/y_axis\"][:]\n",
    "    scaler_names = [n.decode() for n in f[\"MAPS/Scalers/Names\"][:]]\n",
    "    scalers = f[\"MAPS/Scalers/Values\"][:]\n",
    "\n",
    "nelem, nrow, ncol = maps.shape\n",
    "print(f\"Elements: {nelem} -- {names}\")\n",
    "print(f\"Map size: {nrow} x {ncol} pixels\")\n",
    "print(f\"Scan area: {x_axis[-1]-x_axis[0]:.1f} x {y_axis[-1]-y_axis[0]:.1f} um\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-channel statistics and SNR estimation\n",
    "\n",
    "bg_roi = (slice(0, max(1, nrow // 20)), slice(0, max(1, ncol // 20)))  # Top-left corner\n",
    "\n",
    "rows = []\n",
    "for i, name in enumerate(names):\n",
    "    m = maps[i]\n",
    "    bg = m[bg_roi]\n",
    "    noise = np.std(bg) if bg.size > 1 else 1e-10\n",
    "    snr = np.mean(m) / max(noise, 1e-10)\n",
    "    rows.append({\n",
    "        \"Element\": name,\n",
    "        \"Min\": f\"{m.min():.2f}\",\n",
    "        \"Max\": f\"{m.max():.2f}\",\n",
    "        \"Mean\": f\"{m.mean():.2f}\",\n",
    "        \"Median\": f\"{np.median(m):.2f}\",\n",
    "        \"Std\": f\"{m.std():.2f}\",\n",
    "        \"SNR\": f\"{snr:.1f}\",\n",
    "        \"% Zeros\": f\"{100 * (m == 0).mean():.1f}\",\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Per-Element Statistics:\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel histograms\n",
    "\n",
    "n_show = min(nelem, 15)\n",
    "ncols_plot = 5\n",
    "nrows_plot = int(np.ceil(n_show / ncols_plot))\n",
    "\n",
    "fig, axes = plt.subplots(nrows_plot, ncols_plot, figsize=(4 * ncols_plot, 3 * nrows_plot))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(n_show):\n",
    "    ax = axes[i]\n",
    "    data = maps[i].ravel()\n",
    "    pos_data = data[data > 0]\n",
    "    if len(pos_data) > 0:\n",
    "        ax.hist(pos_data, bins=80, log=True, color=\"steelblue\", edgecolor=\"none\")\n",
    "        p99 = np.percentile(pos_data, 99)\n",
    "        ax.axvline(p99, color=\"red\", ls=\"--\", lw=1, label=f\"p99={p99:.1f}\")\n",
    "        ax.legend(fontsize=7)\n",
    "    ax.set_title(names[i], fontsize=10)\n",
    "    ax.set_xlabel(\"Counts/sec\", fontsize=8)\n",
    "\n",
    "for i in range(n_show, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle(\"XRF Channel Histograms (log scale)\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element correlation matrix\n",
    "\n",
    "flat_maps = maps.reshape(nelem, -1)\n",
    "corr = np.corrcoef(flat_maps)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(max(8, nelem * 0.6), max(6, nelem * 0.5)))\n",
    "sns.heatmap(corr, xticklabels=names, yticklabels=names,\n",
    "            cmap=\"RdBu_r\", center=0, vmin=-1, vmax=1,\n",
    "            annot=True, fmt=\".2f\", ax=ax, square=True,\n",
    "            cbar_kws={\"label\": \"Pearson r\"})\n",
    "ax.set_title(\"XRF Element Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Report strongly correlated pairs\n",
    "print(\"\\nStrongly correlated element pairs (|r| > 0.7):\")\n",
    "for i in range(nelem):\n",
    "    for j in range(i + 1, nelem):\n",
    "        if abs(corr[i, j]) > 0.7:\n",
    "            print(f\"  {names[i]:4s} -- {names[j]:4s}:  r = {corr[i, j]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dead/hot pixel detection\n",
    "\n",
    "def detect_bad_pixels(image, threshold=5.0):\n",
    "    \"\"\"Detect pixels deviating from local median by > threshold * MAD.\"\"\"\n",
    "    med = median_filter(image.astype(float), size=3)\n",
    "    diff = np.abs(image.astype(float) - med)\n",
    "    mad = np.median(diff[diff > 0]) if (diff > 0).any() else 1.0\n",
    "    return diff > threshold * max(mad, 1e-10)\n",
    "\n",
    "combined_mask = np.zeros((nrow, ncol), dtype=bool)\n",
    "print(\"Dead/hot pixel detection per element:\")\n",
    "for i, name in enumerate(names):\n",
    "    bad = detect_bad_pixels(maps[i])\n",
    "    n_bad = bad.sum()\n",
    "    combined_mask |= bad\n",
    "    if n_bad > 0:\n",
    "        print(f\"  {name:4s}: {n_bad:5d} bad pixels ({100 * n_bad / (nrow * ncol):.2f}%)\")\n",
    "\n",
    "print(f\"\\nTotal unique bad pixel positions: {combined_mask.sum()}\")\n",
    "\n",
    "# Visualize bad pixel map\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.imshow(combined_mask.astype(int), cmap=\"Reds\", origin=\"lower\",\n",
    "          extent=[x_axis[0], x_axis[-1], y_axis[0], y_axis[-1]])\n",
    "ax.set_title(f\"Combined Bad Pixel Map ({combined_mask.sum()} pixels)\")\n",
    "ax.set_xlabel(\"X (um)\")\n",
    "ax.set_ylabel(\"Y (um)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I0 (incident flux) normalization check\n",
    "\n",
    "if \"I0\" in scaler_names:\n",
    "    i0_idx = scaler_names.index(\"I0\")\n",
    "    i0_map = scalers[i0_idx]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "    \n",
    "    # I0 spatial map\n",
    "    im0 = axes[0].imshow(i0_map, cmap=\"viridis\", origin=\"lower\",\n",
    "                         extent=[x_axis[0], x_axis[-1], y_axis[0], y_axis[-1]])\n",
    "    axes[0].set_title(\"I0 Spatial Map\")\n",
    "    plt.colorbar(im0, ax=axes[0], label=\"Counts\")\n",
    "    \n",
    "    # I0 histogram\n",
    "    axes[1].hist(i0_map.ravel(), bins=100, color=\"steelblue\")\n",
    "    axes[1].set_title(f\"I0 Distribution (CV={i0_map.std()/i0_map.mean():.3f})\")\n",
    "    axes[1].set_xlabel(\"I0 Counts\")\n",
    "    \n",
    "    # Row-averaged I0 (shows beam stability over scan)\n",
    "    i0_row_avg = np.mean(i0_map, axis=1)\n",
    "    axes[2].plot(y_axis, i0_row_avg, \"b-\", lw=0.8)\n",
    "    axes[2].fill_between(y_axis, i0_row_avg * 0.95, i0_row_avg * 1.05,\n",
    "                         alpha=0.2, color=\"orange\", label=\"+/- 5%\")\n",
    "    axes[2].set_xlabel(\"Y position (um)\")\n",
    "    axes[2].set_ylabel(\"Mean I0\")\n",
    "    axes[2].set_title(\"I0 Stability Over Scan\")\n",
    "    axes[2].legend()\n",
    "    \n",
    "    # Check for beam drops\n",
    "    i0_mean = i0_map.mean()\n",
    "    low_i0 = i0_map < 0.5 * i0_mean\n",
    "    if low_i0.any():\n",
    "        print(f\"WARNING: {low_i0.sum()} pixels with I0 < 50% of mean (beam instability)\")\n",
    "    else:\n",
    "        print(\"I0 check passed: no significant beam drops detected.\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"I0 scaler not found. Available scalers: {scaler_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA Summary\n",
    "\n",
    "After running this notebook, you should have assessed:\n",
    "\n",
    "1. **Data dimensions** -- Verified map sizes and element list\n",
    "2. **Per-element statistics** -- Min, max, mean, SNR for each channel\n",
    "3. **Intensity distributions** -- Histogram shapes, dynamic range usage\n",
    "4. **Element correlations** -- Co-localization patterns\n",
    "5. **Dead/hot pixels** -- Identified and counted anomalous pixels\n",
    "6. **I0 stability** -- Checked incident beam normalization\n",
    "\n",
    "**Next steps**: Based on EDA findings, proceed to preprocessing (dead pixel\n",
    "interpolation, background subtraction) and then quantitative analysis\n",
    "(phase mapping, clustering, ROI identification)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
